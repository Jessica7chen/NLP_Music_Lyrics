I say we use this text file as a basic outline to start.
They have a tab named "Projects" we can use to create a more aesthetically pleasing outline with bins "To do", "In Progress", and "Done".
Once I commit this file to Tyra's repository it becomes public for any collaborators, our group, to edit.
I believe it keeps a history of the changes to the files we upload, and you can comment what you've changed to the file when you commit it.
I say we play around with this text file as a way to test how this system works. It seems very similar to Google Drive.
- Luke
----------
Update: After posting I saw there is a button that says "History" in the top right of the window. You can see the comments and history of the file.
This seems very useful for actual code as you can see how it progresses and who progresses it and what their intentions are.
- Luke
----------
Hi Luke, thank you for explaining this is such great detail. Let's see how my comment looks. 
Also I wanted to add that I tried to download and upload the data into my R and my laptop was on the verge of exploding. 
I hope you guys have better luck than I did. 
- Tyra
----------
That's funny. It's 3 GB so there is a lot of data to be unpacked. I'm downloading it now. I can sample the data and upload it to Github so it's
easier on our computers. 3 GB seems overkill to start.
- Luke
----------
I uploaded an outline that is a work in progress. I propose that file to be the file we all use to code on. So, I recommend you save it locally
and prepare your own outline for Wednesday so we can discuss the project further on Wednesday.
Things to consider/research: NLP library to use, model to predict decade, how to use and connect the two.
- Luke
----------
Here's a URL that I posted to the code that I'm basing a lot of my project notes on.
https://www.youtube.com/watch?v=j1V2McKbkLo
- Luke
----------
Ari's project outline:
Steps:
1. Import the song data (API or dataset): (GeniusAPI, MusixMatchAPI, LyricFind API)
2. Clean Data: remove punctuation, stop words, convert to lowercase
3. Feature extraction (or converting words into numbers): 	
      Bag of words: counts word distribution and represents as vector. Focuses on frequency while ignoring order/context
      Word embeddings: captures words with similar meanings and groups them together
      NER: categorizes words (names, places, companiesâ€¦)
      POS: notes the part of speech of different words
4. Decide on a model to use (random forest, decision trees, SVM, neural net)
5. Split data into training and testing and train the model
----------
This is good, I didn't know of NER or POS. Are there any resources you were going off of that I could check out?
Also, for #3 and #2 wouldn't order/context matter if we're doing POS?
- Luke
----------
I am going to be putting the code that I found from Kaggle. I used this code on the old lyric dataset to see if it works.
It did work, but I'm not sure if it contributes to the goal that we are trying to accomplish.
It does NLP for topic modeling. I include a link below and added the code to the R codespace. 
Link: https://www.kaggle.com/code/rtatman/nlp-in-r-topic-modelling/notebook
- Tyra
----------
I sampled the dataset to only include 50k english titles. There were other characters (Russian was what I saw) that would've
made our project a little trickier. The link to it is below. The final file size is 87mb and we can resample if that's too large.
https://www.dropbox.com/s/h7w6jc1r85ogcqd/song_lyrics_sample.csv?dl=0
I also uploaded the code to sampling the df if anyone was curious.
- Luke
----------
I just created a file called "Exploratory Data Analysis" for us to make graphs that are less NLP related and more like regular data analysis. 
Things like most common words by decade might be an interesting addition to our presentation. 
- Ari
----------
Structure of our Presentation 
Include a timeline of how we got to our final product 
-Proposal
-How we went about the proposal
-How the proposal has changed while we try to improve it

Luke & Ari - Main Code
Jessica & Tyra - Report & Analysis - Will wait for Anish's Cleaned Data
Anish - Cleaning & Grouping Code

- Tyra 
----------
I updated the main file. I cleaned up the code (we didn't need tidyverse), made things into functions, and got up until we deploy the model. Ari your code was big help. I am tinkering with code to make the messy data more regular, and I'm very close to being finished. I wrote a few plot functions into them so we can see what it's doing, however Tyra's Kaggle code has much prettier plots. When I finish up we'll try running the model. We should try a few different models.
Anish and Ari can you do some research on different algorithms to deploy?
I'd like to try KNN. RandomForest is good, but it's based on classification models which I am skeptical of for this project. Tyra and Jessica when I post the new new code you should check out the plots, and get familiar with the dataframe generateTDM() creates, that's where we'll get most of our fun information from. I'm going to post a link to a 'wordcloud' article to look into. Anyway, I'm going to bed.
https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a
-Luke
----------
I updated the code, got the new function to work. It posts two plots that show you what's going on. It takes some time to run on my laptop, so it might take some time to run on yours too. I can explain it over our next zoom. Ari can you run this code through the model and see how it works, if it works?
-Luke
----------
I posted in the groupme, but want to post something a little more elaborate here. I don't think my original idea worked with making the data uniform. It does make the data 'uniform' but I was wrong in how the model works. It doesn't matter if the data is uniform. The reason the new model was more accurate was because of the skew. I ran a test with the original DTM test_df - not uniform - and it provided similar results to Ari's model, 51% accuracy. I also tried running KNN overnight with the df and it didn't finish. I tried SVM with less words and it also failed to finish. Looking at the words the model doesn't really pick out words that 'stick out'. Also, after changing removeSparseTerms(0.99) to removeSparseTerms(0.9) it provided ~100ish terms, but they were all basic. BUT, it would help for Jessica and Tyra to work with the small dataset to make functions to provide visuals for the dataset. We should find a number that works after manually looking over the words it includes. I have a feeling it just cuts out the most and least popular terms and keeps (0.99) or (0.9) of the total terms. It's pretty much a confidence interval.
-Luke
----------
Tyra and Jessica. Try this code on the DTM, it'll give you the words and their counts of the category you choose from [1:10] or whatever other numbers you input.
sort(colSums(df[df$category=='rap',-length(df)]),decreasing = T)[1:10]
I ran the genres through the model, it's more accurate than decades. There's only 6 genres. It mainly guesses rap or pop and gets everything else wrong, especially country and rb. It mainly seperates pop and rap from "love" and an assortment of cursewords. I think we should start learning from the data and think about why the correlation between seperate words and the whole genre is limited. Probably a stronger association with artists.
-Luke
----------
Thanks for all the codes! There are two problems I met after I ran all the code. Since Luke mentioned that there should be two plots, but I only got one. The one I have now is about old values(decade & count). Besides that, I also ran the code Luke provided for DTM. sort(colSums(df[df$category=='rap',-length(df)]),decreasing = T)[1:10]. I get an output of all zeros, can't find out what went wrong so far.
-Jessica
----------
I'll post the code I'm currently running, it's more basic and straight forward. I'll post it seperately as 'Gutted Lyric to Decade'. Should work better.
-Luke
----------
Another update. I sampled the df uniformly by both decade and genre. Feel free to play around with it. I'd advise using the "Gutted Lyrics to Decade" code. It should help KNN which I've gotten to work. At the very least the predictions will get better. I also did another thing to just fool around. I made vectors of the percentages of the words for each decade and only trained the model on that. It was horrendously innaccurate at about 17% on KNN haha. I'm going to fool around with removeSparseTerms too. But I'm going to take a break for a little. I'm not sure if anyone is reading this-lol.
https://www.dropbox.com/s/zeakk9nsn13clw6/songs_uniformbydecade.csv?dl=0 
https://www.dropbox.com/s/v7augxdl6xqcozz/songs_uniformbygenre.csv?dl=0 
-Luke
----------
I updated the code for Stat Learning Project Add Decade. I added the code for creating wordclouds for each genre. 
-Anish
