#This is for doing analysis seperate from the direct NLP. We want pretty graphs that are easy to understand. Inspired by: 
#https://towardsdatascience.com/how-we-used-nltk-and-nlp-to-predict-a-songs-genre-from-its-lyrics-54e338ded537

#Kaggle Code - T
library(readr)
lyricdata <- read_csv("/Users/tyralassiter/Downloads/tcc_ceds_music.csv", 
    col_types = cols(...1 = col_skip(), len = col_skip(), 
        dating = col_skip(), violence = col_skip(), 
        `world/life` = col_skip(), `night/time` = col_skip(), 
        `shake the audience` = col_skip(), 
        `family/gospel` = col_skip(), romantic = col_skip(), 
        communication = col_skip(), obscene = col_skip(), 
        music = col_skip(), `movement/places` = col_skip(), 
        `light/visual perceptions` = col_skip(), 
        `family/spiritual` = col_skip(), 
        `like/girls` = col_skip(), sadness = col_skip(), 
        feelings = col_skip(), danceability = col_skip(), 
        loudness = col_skip(), acousticness = col_skip(), 
        instrumentalness = col_skip(), valence = col_skip(), 
        energy = col_skip(), topic = col_skip(), 
        age = col_skip()))
View(lyricdata)

# read in the libraries we're going to use
library(tidyverse) # general utility & workflow functions
library(tidytext) # tidy implimentation of NLP methods
library(topicmodels) # for LDA topic modelling 
library(tm) # general text mining functions, making document term matrixes
library(SnowballC) # for stemming

top_terms_by_topic_LDA <- function(input_text, # should be a columm from a dataframe
                                   plot = T, # return a plot? TRUE by defult
                                   number_of_topics = 4)# number of topics (4 by default)
{    
    # create a corpus (type of object expected by tm) and document term matrix
    Corpus <- Corpus(VectorSource(input_text)) # make a corpus object
    DTM <- DocumentTermMatrix(Corpus) # get the count of words/document

    # remove any empty rows in our document term matrix (if there are any 
    # we'll get an error when we try to run our LDA)
    unique_indexes <- unique(DTM$i) # get the index of each unique value
    DTM <- DTM[unique_indexes,] # get a subset of only those indexes
    
    # preform LDA & get the words/topic in a tidy text format
    lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))
    topics <- tidy(lda, matrix = "beta")

    # get the top ten terms for each topic
    top_terms <- topics  %>% # take the topics data frame and..
      group_by(topic) %>% # treat each topic as a different group
      top_n(10, beta) %>% # get the top 10 most informative words
      ungroup() %>% # ungroup
      arrange(topic, -beta) # arrange words in descending informativeness

    # if the user asks for a plot (TRUE by default)
    if(plot == T){
        # plot the top ten terms for each topic in order
        top_terms %>% # take the top terms
          mutate(term = reorder(term, beta)) %>% # sort terms by beta value 
          ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme
          geom_col(show.legend = FALSE) + # as a bar plot
          facet_wrap(~ topic, scales = "free") + # which each topic in a seperate plot
          labs(x = NULL, y = "Beta") + # no x label, change y label 
          coord_flip() # turn bars sideways
    }else{ 
        # if the user does not request a plot
        # return a list of sorted terms instead
        return(top_terms)
    }
}

top_terms_by_topic_LDA(lyricdata$lyrics, number_of_topics = 2)

# create a document term matrix to clean
lyricsCorpus <- Corpus(VectorSource(lyricdata$lyrics)) 
lyricsDTM <- DocumentTermMatrix(lyricsCorpus)

# convert the document term matrix to a tidytext corpus
lyricsDTM_tidy <- tidy(lyricsDTM)

# I'm going to add my own custom stop words that I don't think will be
# very informative in hotel reviews
#stop_words 

# remove stopwords
lyricsDTM_tidy_cleaned <- lyricsDTM_tidy #%>% # take our tidy dtm and...
    #anti_join(stop_words, by = c("term" = "word")) # remove English stopwords and...

# reconstruct cleaned documents (so that each word shows up the correct number of times)
cleaned_documents <- lyricsDTM_tidy_cleaned %>%
    group_by(document) %>% 
    mutate(terms = toString(rep(term, count))) %>%
    select(document, terms) %>%
    unique()

# check out what the cleaned documents look like (should just be a bunch of content words)
# in alphabetic order
head(cleaned_documents)

top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
    # name for the column we're going to unnest_tokens_ to
    # (you only need to worry about enquo stuff if you're
    # writing a function using using tidyverse packages)
    group_column <- enquo(group_column)
    text_column <- enquo(text_column)
    
    # get the count of each word in each review
    words <- text_df %>%
      unnest_tokens(word, !!text_column) %>%
      count(!!group_column, word) %>% 
      ungroup()

    # get the number of words per text
    total_words <- words %>% 
      group_by(!!group_column) %>% 
      summarize(total = sum(n))

    # combine the two dataframes we just made
    words <- left_join(words, total_words)

    # get the tf_idf & order the words by degree of relevence
    tf_idf <- words %>%
      bind_tf_idf(word, !!group_column, n) %>%
      select(-total) %>%
      arrange(desc(tf_idf)) %>%
      mutate(word = factor(word, levels = rev(unique(word))))
    
    if(plot == T){
        # convert "group" into a quote of a name
        # (this is due to funkiness with calling ggplot2
        # in functions)
        group_name <- quo_name(group_column)
        
        # plot the 10 most informative terms per topic
        tf_idf %>% 
          group_by(!!group_column) %>% 
          top_n(10) %>% 
          ungroup %>%
          ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
          geom_col(show.legend = FALSE) +
          labs(x = NULL, y = "tf-idf") +
          facet_wrap(reformulate(group_name), scales = "free") +
          coord_flip()
    }else{
        # return the entire tf_idf dataframe
        return(tf_idf)
    }
}
